paths:
  output_dir: /results/off_policy_sweep/e4_tb64_ga16
training:
  wandb_run_name: off_policy_e4_tb64_ga16
  wandb_tags:
    - grpo
    - h100
    - modal
    - off_policy_sweep
    - broad_sweep

  use_compile: false
  track_peak_memory: false
  use_gradient_checkpointing: false
  use_bnb_adamw8bit: false
  use_vllm_sleep_mode: true
  old_log_probs_train_size: 4
  loss_type: grpo_clip
  n_grpo_steps: 50
  learning_rate: 3e-5
  checkpoint_interval: 8
  normalize_mode: mean
  use_std_normalization: true

  # aggressive off-policy via both: 4 epochs, quarter batch -> 16 opt steps per GRPO step
  epochs_per_rollout_batch: 4
  train_batch_size: 64
  gradient_accumulation_steps: 16   # micro_batch_size = 64/16 = 4
vllm:
  gpu_memory_utilization: 0.2
