{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken and modified from https://github.com/karpathy/build-nanogpt/blob/master/play.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = \"124M\"\n",
    "log_file = \"log/log.txt\"\n",
    "\n",
    "loss_baseline = {\n",
    "    \"124M\": 3.2924,\n",
    "}[sz]\n",
    "\n",
    "hella2_baseline = { # HellaSwag for GPT-2\n",
    "    \"124M\": 0.294463,\n",
    "    \"350M\": 0.375224,\n",
    "    \"774M\": 0.431986,\n",
    "    \"1558M\": 0.488946,\n",
    "}[sz]\n",
    "hella3_baseline = { # HellaSwag for GPT-3\n",
    "    \"124M\": 0.337,\n",
    "    \"350M\": 0.436,\n",
    "    \"774M\": 0.510,\n",
    "    \"1558M\": 0.547,\n",
    "}[sz]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913dbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the log file\n",
    "with open(log_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# parse the individual lines, group by stream (train,val,hella)\n",
    "streams = {}\n",
    "for line in lines:\n",
    "    step, stream, val = line.strip().split()\n",
    "    if stream not in streams:\n",
    "        streams[stream] = {}\n",
    "    streams[stream][int(step)] = float(val)\n",
    "\n",
    "# convert each stream from {step: val} to (steps[], vals[])\n",
    "streams_xy = {}\n",
    "for k, v in streams.items():\n",
    "    # get all (step, val) items, sort them\n",
    "    xy = sorted(list(v.items()))\n",
    "    # unpack the list of tuples to tuple of lists\n",
    "    streams_xy[k] = list(zip(*xy))\n",
    "\n",
    "# make sure to remove : from the end of the keys\n",
    "streams_xy = {k.rstrip(':'): v for k, v in streams_xy.items()}\n",
    "print(streams_xy.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f864115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Panel 1: losses: both train and val\n",
    "plt.subplot(121)\n",
    "xs, ys = streams_xy[\"train_loss\"] # training loss\n",
    "ys = np.array(ys)\n",
    "xs = np.array(xs)\n",
    "plt.plot(xs / 1000, ys, label=f'gpt-2 implement ({sz}) train loss', color='royalblue', linewidth=2)\n",
    "print(\"Min Train Loss:\", min(ys))\n",
    "\n",
    "xs, ys = streams_xy[\"val_loss\"] # validation loss\n",
    "xs = np.array(xs)\n",
    "plt.plot(xs / 1000, ys, label=f'gpt-2 implement ({sz}) val loss', color='darkorange', linewidth=2)\n",
    "print(\"Min Validation Loss:\", min(ys))\n",
    "\n",
    "# horizontal line at GPT-2 baseline\n",
    "if loss_baseline is not None:\n",
    "    plt.axhline(y=loss_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) val loss\")\n",
    "\n",
    "plt.xlabel(\"Steps (K)\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.ylim(top=4.0)\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(\"Loss\", fontsize=16)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Panel 2: HellaSwag eval\n",
    "plt.subplot(122)\n",
    "xs, ys = streams_xy[\"hella_norm\"] # HellaSwag eval\n",
    "ys = np.array(ys)\n",
    "xs = np.array(xs)\n",
    "plt.plot(xs / 1000, ys, label=f\"gpt-2 implement ({sz})\", color='royalblue', linewidth=2)\n",
    "print(\"Max Hellaswag eval:\", max(ys))\n",
    "\n",
    "# horizontal line at GPT-2 baseline\n",
    "if hella2_baseline:\n",
    "    plt.axhline(y=hella2_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) baseline\")\n",
    "if hella3_baseline:\n",
    "    plt.axhline(y=hella3_baseline, color='g', linestyle='--', label=f\"OpenAI GPT-3 ({sz}) baseline\")\n",
    "\n",
    "plt.xlabel(\"Steps (K)\", fontsize=14)\n",
    "plt.ylabel(\"HellaSwag Accuracy\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(\"HellaSwag Eval\", fontsize=16)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "# save the plot\n",
    "# plt.savefig(f\"images/gpt-2-implement-baseline.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29313350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "wandb_entity = \"garg-aayush\"\n",
    "wandb_project = \"pre-training\"\n",
    "run_names = [\"gpt2-baseline\", \"gpt2-rope\"]\n",
    "cols_to_keep = ['step', 'val/loss', 'train/loss', 'val/hella_norm']\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "runs_path = f\"{wandb_entity}/{wandb_project}\"\n",
    "print(f\"Fetching from: {runs_path}\")\n",
    "    \n",
    "runs = api.runs(runs_path)\n",
    "    \n",
    "# Filter runs if specified\n",
    "if run_names:\n",
    "    runs = [run for run in runs if run.name in run_names]\n",
    "    \n",
    "# Dictionary to store all data\n",
    "all_histories = {}\n",
    "    \n",
    "    \n",
    "for run in runs:\n",
    "    print(f\"\\nProcessing: {run.name}\")\n",
    "    print(f\"  Run ID: {run.id}\")\n",
    "    print(f\"  State: {run.state}\")\n",
    "        \n",
    "    # Fetch complete history\n",
    "    print(\"  Fetching history...\", end=\"\", flush=True)\n",
    "    history = run.history(samples=100000)  # Large number to get all samples\n",
    "    print(f\" Got {len(history)} datapoints\")\n",
    "        \n",
    "    # Add metadata columns\n",
    "    history['run_name'] = run.name\n",
    "    history['run_id'] = run.id\n",
    "        \n",
    "    # Store in dictionary\n",
    "    all_histories[run.name] = history\n",
    "    \n",
    "    \n",
    "baseline_df = all_histories['gpt2-baseline'][cols_to_keep]\n",
    "rope_df = all_histories['gpt2-rope'][cols_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Panel 1: losses: both train and val\n",
    "plt.subplot(121)\n",
    "xs_baseline, ys_baseline = baseline_df[\"step\"], baseline_df[\"train/loss\"]\n",
    "xs_rope, ys_rope = rope_df[\"step\"], rope_df[\"train/loss\"]\n",
    "\n",
    "# Apply running average\n",
    "# ys_baseline = ys_baseline.rolling(window=10, min_periods=1).mean()\n",
    "# ys_rope = ys_rope.rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "xs_baseline = np.array(xs_baseline)\n",
    "xs_rope = np.array(xs_rope)\n",
    "ys_baseline = np.array(ys_baseline)\n",
    "ys_rope = np.array(ys_rope)\n",
    "plt.plot(xs_baseline / 1000, ys_baseline, label=f'gpt2-baseline train loss ({sz})', color='royalblue', linewidth=2)\n",
    "plt.plot(xs_rope / 1000, ys_rope, label=f'gpt2-rope train loss ({sz})', color='lightblue', linewidth=2)\n",
    "print(\"Min Baseline Train Loss:\", min(ys_baseline))\n",
    "print(\"Min Rope Train Loss:\", min(ys_rope))\n",
    "\n",
    "# Filter out NaN values for baseline validation data\n",
    "baseline_val_mask = baseline_df[\"val/loss\"].notna()\n",
    "xs_val_baseline = baseline_df[baseline_val_mask][\"step\"]\n",
    "ys_val_baseline = baseline_df[baseline_val_mask][\"val/loss\"]\n",
    "\n",
    "# Filter out NaN values for rope validation data\n",
    "rope_val_mask = rope_df[\"val/loss\"].notna()\n",
    "xs_val_rope = rope_df[rope_val_mask][\"step\"]\n",
    "ys_val_rope = rope_df[rope_val_mask][\"val/loss\"]\n",
    "\n",
    "xs_val_baseline = np.array(xs_val_baseline)\n",
    "xs_val_rope = np.array(xs_val_rope)\n",
    "ys_val_baseline = np.array(ys_val_baseline)\n",
    "ys_val_rope = np.array(ys_val_rope)\n",
    "plt.plot(xs_val_baseline / 1000, ys_val_baseline, label=f'gpt2-baseline val loss ({sz})', color='darkorange', linewidth=2)\n",
    "plt.plot(xs_val_rope / 1000, ys_val_rope, label=f'gpt2-rope val loss ({sz})', color='red', linewidth=2)\n",
    "print(\"Min Validation Loss:\", min(ys_val_baseline))\n",
    "print(\"Min Rope Validation Loss:\", min(ys_val_rope))\n",
    "\n",
    "\n",
    "# horizontal line at GPT-2 baseline\n",
    "if loss_baseline is not None:\n",
    "    plt.axhline(y=loss_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) val loss\")\n",
    "\n",
    "plt.xlabel(\"Steps (K)\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.ylim(top=4.0)\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(\"Loss\", fontsize=16)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "\n",
    "\n",
    "# Panel 2: HellaSwag eval\n",
    "plt.subplot(122)\n",
    "xs_baseline, ys_baseline = baseline_df[\"step\"], baseline_df[\"val/hella_norm\"]\n",
    "xs_rope, ys_rope = rope_df[\"step\"], rope_df[\"val/hella_norm\"]\n",
    "# remove NaN values\n",
    "xs_baseline = xs_baseline[~np.isnan(ys_baseline)]\n",
    "ys_baseline = ys_baseline[~np.isnan(ys_baseline)]\n",
    "xs_rope = xs_rope[~np.isnan(ys_rope)]\n",
    "ys_rope = ys_rope[~np.isnan(ys_rope)]\n",
    "\n",
    "xs_baseline = np.array(xs_baseline)\n",
    "xs_rope = np.array(xs_rope)\n",
    "ys_baseline = np.array(ys_baseline)\n",
    "ys_rope = np.array(ys_rope)\n",
    "plt.plot(xs_baseline / 1000, ys_baseline, label=f\"gpt2-baseline ({sz})\", color='darkgreen', linewidth=2)\n",
    "plt.plot(xs_rope / 1000, ys_rope, label=f\"gpt2-rope ({sz})\", color='darkblue', linewidth=2)\n",
    "print(\"Max Hellaswag eval:\", max(ys_baseline))\n",
    "print(\"Max Hellaswag eval:\", max(ys_rope))\n",
    "\n",
    "# horizontal line at GPT-2 baseline\n",
    "if hella2_baseline:\n",
    "    plt.axhline(y=hella2_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) baseline\")\n",
    "if hella3_baseline:\n",
    "    plt.axhline(y=hella3_baseline, color='g', linestyle='--', label=f\"OpenAI GPT-3 ({sz}) baseline\")\n",
    "\n",
    "plt.xlabel(\"Steps (K)\", fontsize=14)\n",
    "plt.ylabel(\"HellaSwag Accuracy\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(\"HellaSwag Eval\", fontsize=16)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "# save the plot\n",
    "plt.savefig(\"images/gpt-2-implement-compare.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c685321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
