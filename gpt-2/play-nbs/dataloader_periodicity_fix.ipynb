{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf311a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "filename = \"../shards/finewebedu10T_train_0001.npy\"\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "eot = enc._special_tokens[\"<|endoftext|>\"]  # end of text token\n",
    "print(eot)\n",
    "\n",
    "np_tensor = np.load(filename, mmap_mode='r')\n",
    "t = torch.tensor(np_tensor, dtype=torch.long)\n",
    "print(t.shape)\n",
    "\n",
    "doc_breaks = (t == eot).nonzero().flatten().tolist()\n",
    "\n",
    "# Split on EOT\n",
    "doc_breaks = (t == eot).nonzero().flatten().tolist()\n",
    "print(\"total eots\", len(doc_breaks))\n",
    "docs, start = [], 0\n",
    "for end in doc_breaks:\n",
    "    docs.append(t[start:end+1])  # include EOT\n",
    "    start = end + 1\n",
    "if start < len(t):  # last doc without trailing EOT\n",
    "    docs.append(t[start:])\n",
    "# print few docs\n",
    "for i,doc in enumerate(docs[:3]):\n",
    "    print(i, len(doc))\n",
    "rng = np.random.RandomState(42)\n",
    "rng.shuffle(docs)\n",
    "for i,doc in enumerate(docs[:3]):\n",
    "    print(i, len(doc))\n",
    "out_tensor = torch.cat(docs, dim=0)\n",
    "# get total eots\n",
    "total_eots = (out_tensor == eot).sum().item()\n",
    "print(\"total eots\", total_eots)\n",
    "print(out_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_offset = 0\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T, process_rank, num_processes, split, data_root='../shards', seed=42):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.process_rank = process_rank\n",
    "        self.num_processes = num_processes\n",
    "        assert split in [\"train\", \"val\"], f\"Invalid split: {split}\"\n",
    "        self.split = split\n",
    "        self.rng = np.random.RandomState(seed+seed_offset)\n",
    "        self.eot = enc._special_tokens[\"<|endoftext|>\"]  # end of text token\n",
    "        \n",
    "        # get the shards filenames\n",
    "        shards = [s for s in os.listdir(data_root) if self.split in s]\n",
    "        shards = sorted(shards)\n",
    "        shards = [os.path.join(data_root, s) for s in shards]\n",
    "        self.shards = shards\n",
    "        print(self.shards)\n",
    "        # shuffle the shards\n",
    "        self.rng.shuffle(self.shards)\n",
    "        assert len(shards) > 0, f\"No shards found for split: {self.split}\"\n",
    "        print(self.shards)\n",
    "\n",
    "        # load the dataset\n",
    "        self.cur_shard = 0\n",
    "        self.tokens = self._load_tokens(self.shards[self.cur_shard])\n",
    "        self.cur_pos = self.process_rank * (self.B * self.T)\n",
    "\n",
    "        \n",
    "    def get_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.cur_pos : self.cur_pos + B * T + 1]\n",
    "        x = buf[:-1].view(B, T)  # input to the model\n",
    "        y = buf[1:].view(B, T)  # output of the model\n",
    "        # advance position\n",
    "        self.cur_pos += B * T * self.num_processes\n",
    "        \n",
    "        # if loading next batch is out of bounds, load the next shard\n",
    "        if self.cur_pos + B * T * self.num_processes + 1 > len(self.tokens):\n",
    "            self.cur_shard = (self.cur_shard + 1) % len(self.shards)\n",
    "            self.tokens = self._load_tokens(self.shards[self.cur_shard])\n",
    "            self.cur_pos = self.process_rank * (self.B * self.T)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def _load_tokens(self, filename):\n",
    "        # memory mapping for efficiency\n",
    "        np_tensor = np.load(filename, mmap_mode='r')\n",
    "        # For validation split, return tokens as-is without shuffling\n",
    "        if self.split == \"val\":\n",
    "            return torch.tensor(np_tensor, dtype=torch.long)\n",
    "        else:\n",
    "            # For training split, shuffle documents to reduce temporal patterns\n",
    "            t = torch.tensor(np_tensor, dtype=torch.long)\n",
    "            # Split the token sequence into individual documents at end-of-text markers\n",
    "            doc_breaks = (t == self.eot).nonzero().flatten().tolist()\n",
    "            docs, start = [], 0 \n",
    "            # Extract each document including its EOT token\n",
    "            for end in doc_breaks:\n",
    "                docs.append(t[start:end+1])  # include EOT\n",
    "                start = end + 1\n",
    "            if start < len(t):  # last doc without trailing EOT\n",
    "                docs.append(t[start:])\n",
    "            # Randomly shuffle the order of documents to break temporal patterns\n",
    "            self.rng.shuffle(docs)\n",
    "            # Concatenate all shuffled documents back into a single tensor\n",
    "            return torch.cat(docs, dim=0)\n",
    "    def reset(self):\n",
    "        self.cur_shard = 0\n",
    "        self.tokens = self._load_tokens(self.shards[self.cur_shard])\n",
    "        self.cur_pos = self.process_rank * (self.B * self.T)\n",
    "\n",
    "train_loader = DataLoaderLite(B=4, T=1024, process_rank=0, num_processes=1, split=\"train\")\n",
    "val_loader = DataLoaderLite(B=4, T=1024, process_rank=0, num_processes=1, split=\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8cc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f227d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
