{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec99cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from bpe_encode_rust import PyBpeEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f38fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_size(bytes_size):\n",
    "    \"\"\"Format bytes to human readable format\"\"\"\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if bytes_size < 1024.0:\n",
    "            return f\"{bytes_size:.2f} {unit}\"\n",
    "        bytes_size /= 1024.0\n",
    "    return f\"{bytes_size:.2f} TB\"\n",
    "\n",
    "def print_metrics(encode_time, num_tokens, chars_per_sec, bytes_per_sec, tokens_per_sec, num_chars, num_bytes):\n",
    "    print(f\"Encoding completed in {encode_time:.4f} seconds, Tokens: {num_tokens:,}\")\n",
    "    # Calculate metrics\n",
    "    print(\"-\"*40)\n",
    "    print(\"Performance Metrics\")\n",
    "    print(\"-\"*40)\n",
    "    # throughput\n",
    "    print(\"Throughput:\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"  {chars_per_sec:,.0f} chars/sec\")\n",
    "    print(f\"  {format_size(bytes_per_sec)}/sec\")\n",
    "    print(f\"  {tokens_per_sec:,.0f} tokens/sec\")\n",
    "    # compression\n",
    "    print(\"-\"*40)\n",
    "    print(\"Compression:\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"  {num_chars / num_tokens:.2f} chars/token\")\n",
    "    print(f\"  {num_bytes / num_tokens:.2f} bytes/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce738e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input file\n",
    "file_path = \"data/TinyStoriesV2-GPT4-valid.txt\"\n",
    "print(f\"Reading input file: {file_path}\")\n",
    "with open(file_path, \"r\") as f:\n",
    "    text = f.read()\n",
    "num_chars = len(text)\n",
    "num_bytes = len(text.encode('utf-8'))\n",
    "\n",
    "# print(f\"File read in {read_time:.4f} seconds\")\n",
    "print(f\"Characters: {num_chars:,}\")\n",
    "print(f\"Bytes (UTF-8): {num_bytes:,} ({format_size(num_bytes)})\")\n",
    "print(f\"Lines: {text.count(chr(10)):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306634d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the parquet file\n",
    "file_path = \"data/013_00000.parquet\"\n",
    "nrows = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f08ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input file\n",
    "print(f\"Reading input file: {file_path}\")\n",
    "read_start = time.time()\n",
    "df = pd.read_parquet(file_path)\n",
    "text_column = df['text'][:nrows]\n",
    "print(len(text_column))\n",
    "text = \"<|endoftext|>\"\n",
    "for t in text_column:\n",
    "    t += \"<|endoftext|>\"\n",
    "    text += t\n",
    "read_time = time.time() - read_start\n",
    "\n",
    "num_chars = len(text)\n",
    "num_bytes = len(text.encode('utf-8'))\n",
    "\n",
    "print(f\"File read in {read_time:.4f} seconds\")\n",
    "print(f\"Characters: {num_chars:,}\")\n",
    "print(f\"Bytes (UTF-8): {num_bytes:,} ({format_size(num_bytes)})\")\n",
    "print(f\"Lines: {text.count(chr(10)):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken (gpt-2)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encode_start = time.time()\n",
    "tokens = tokenizer.encode(text, allowed_special='all')\n",
    "encode_time = time.time() - encode_start\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "chars_per_sec = num_chars / encode_time\n",
    "bytes_per_sec = num_bytes / encode_time\n",
    "tokens_per_sec = num_tokens / encode_time\n",
    "\n",
    "print_metrics(encode_time, num_tokens, chars_per_sec, bytes_per_sec, tokens_per_sec, num_chars, num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b50395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken (gpt-2)\n",
    "tokenizer = PyBpeEncode()\n",
    "tokenizer.load('data/tinystoriesv2-gpt4-train-2048.model')\n",
    "encode_start = time.time()\n",
    "tokens = tokenizer.encode(text, 'all')\n",
    "encode_time = time.time() - encode_start\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "chars_per_sec = num_chars / encode_time\n",
    "bytes_per_sec = num_bytes / encode_time\n",
    "tokens_per_sec = num_tokens / encode_time\n",
    "\n",
    "print_metrics(encode_time, num_tokens, chars_per_sec, bytes_per_sec, tokens_per_sec, num_chars, num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken (gpt-2)\n",
    "tokenizer = PyBpeEncode()\n",
    "tokenizer.load('data/tinystoriesv2-gpt4-train-8192.model')\n",
    "encode_start = time.time()\n",
    "tokens = tokenizer.encode(text, 'all')\n",
    "encode_time = time.time() - encode_start\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "chars_per_sec = num_chars / encode_time\n",
    "bytes_per_sec = num_bytes / encode_time\n",
    "tokens_per_sec = num_tokens / encode_time\n",
    "\n",
    "print_metrics(encode_time, num_tokens, chars_per_sec, bytes_per_sec, tokens_per_sec, num_chars, num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken (gpt-2)\n",
    "tokenizer = PyBpeEncode()\n",
    "tokenizer.load('data/tinystoriesv2-gpt4-train-16384.model')\n",
    "encode_start = time.time()\n",
    "tokens = tokenizer.encode(text, 'all')\n",
    "encode_time = time.time() - encode_start\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "chars_per_sec = num_chars / encode_time\n",
    "bytes_per_sec = num_bytes / encode_time\n",
    "tokens_per_sec = num_tokens / encode_time\n",
    "\n",
    "print_metrics(encode_time, num_tokens, chars_per_sec, bytes_per_sec, tokens_per_sec, num_chars, num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0faba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken (gpt-2)\n",
    "tokenizer = PyBpeEncode()\n",
    "tokenizer.load('data/fineweb-000_00003-gpt4-train-16384.model')\n",
    "encode_start = time.time()\n",
    "tokens = tokenizer.encode(text, 'all')\n",
    "encode_time = time.time() - encode_start\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "chars_per_sec = num_chars / encode_time\n",
    "bytes_per_sec = num_bytes / encode_time\n",
    "tokens_per_sec = num_tokens / encode_time\n",
    "\n",
    "print_metrics(encode_time, num_tokens, chars_per_sec, bytes_per_sec, tokens_per_sec, num_chars, num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9905e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
