# MMLU Evaluation Configuration

evaluator: MMLU

evaluator_params:
  val_dir: data/eval_data/mmlu
  mmlu_question_file: data/mmlu_question.prompt
  system_prompt_file: data/zero_shot_system_prompt.prompt
  results_dir: results/instruct/baseline
  eval_filename: baseline_mmlu_results.jsonl
  headers:
    - question
    - A
    - B
    - C
    - D
    - answer

model_name: meta-llama/Llama-3.1-8B

sampling_params:
  temperature: 0.0
  top_p: 1.0
  max_tokens: 128
  stop:
    - "```"

model_params:
  max_model_len: 2048
  max_num_seqs: 64

save_results: true
