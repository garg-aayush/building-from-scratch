# Direct Preference Optimization (DPO) from scratch

This folder contains **from-scratch implementation** of Direct Preference Optimization (DPO), loosely following Stanford's [CS336 Supplementary Assignment 5](https://github.com/heng380/cs336_assignment-5/blob/main/cs336_spring2025_assignment5_supplement_safety_rlhf.pdf).

